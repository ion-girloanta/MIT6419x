{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unnecessary-louis",
   "metadata": {},
   "source": [
    "## L6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cutting-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-canberra",
   "metadata": {},
   "source": [
    "### 5. Review: Empirical Mean and Covariance Matrix of a Vector Data Set I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "protected-justice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 4, 7],\n",
       "       [2, 8, 1],\n",
       "       [3, 1, 1],\n",
       "       [9, 7, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Sample Covariance for a Data Set of Vectors\n",
    "# empirical covariance matrix or sample covariance matrix\n",
    "x1 = np.array([8,4,7])\n",
    "x2 = np.array([2,8,1])\n",
    "x3 = np.array([3,1,1])\n",
    "x4 = np.array([9,7,4])\n",
    "\n",
    "X = np.vstack([x1,x2,x3,x4])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "loved-associate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.5 , 5.  , 3.25]),\n",
       " array([[30.25  , 27.5   , 17.875 ],\n",
       "        [27.5   , 25.    , 16.25  ],\n",
       "        [17.875 , 16.25  , 10.5625]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar_X = np.mean(X, axis=0)\n",
    "bar_X, np.outer(bar_X, bar_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "speaking-revision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample covariance matrix= \n",
      " [[9.25   1.     6.375 ]\n",
      " [1.     7.5    0.    ]\n",
      " [6.375  0.     6.1875]], S == S_np? True\n"
     ]
    }
   ],
   "source": [
    "S = (np.mean([np.outer(x1, x1),np.outer(x2, x2),np.outer(x3, x3),np.outer(x4, x4)],axis=0))-np.outer(bar_X, bar_X)\n",
    "# np.cov is feature wise cov if we want sample wise, DATA.T\n",
    "S_np=np.cov(X.T,bias=True)\n",
    "\n",
    "print(f'sample covariance matrix= \\n {S}, S == S_np? {(S==S_np).all()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "informative-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_matrix(X):\n",
    "    n=X.shape[0]\n",
    "    S = 1/n*(X.T@(np.identity(X.shape[0])-1/n*np.ones((n,n)))@X)\n",
    "    return np.squeeze(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fourth-basket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample covariance matrix= \n",
      " [[9.25   1.     6.375 ]\n",
      " [1.     7.5    0.    ]\n",
      " [6.375  0.     6.1875]], S == S_np? True\n"
     ]
    }
   ],
   "source": [
    "# other solution\n",
    "n=X.shape[0]\n",
    "S = cov_matrix(X)\n",
    "print(f'sample covariance matrix= \\n {S}, S == S_np? {(S==S_np).all()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-switzerland",
   "metadata": {},
   "source": [
    "### 6. Empirical Mean and Covariance Matrix of a Vector Data Set II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "forward-breed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66666667, -0.33333333, -0.33333333],\n",
       "       [-0.33333333,  0.66666667, -0.33333333],\n",
       "       [-0.33333333, -0.33333333,  0.66666667]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H Orthogonal Projection Matrix\n",
    "n=3\n",
    "H = np.identity(n)-1/n*np.outer(np.ones(n),np.ones(n)) \n",
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-childhood",
   "metadata": {},
   "source": [
    "- For any positive integer ùëò and any vector $ùê± \\in \\mathbb{R}^n$, we have $ùêª^k ùê±= ùêªùê±$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "authorized-marathon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.11213535, -0.03832701, -0.07380834]),\n",
       " array([ 0.11213535, -0.03832701, -0.07380834]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random(n)\n",
    "H@x, H@H@H@H@H@x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-tamil",
   "metadata": {},
   "source": [
    "- The matrix $ùêª$  is a projection onto the subspace of vectors perpendicular to the vector $\\vec{1} \\in \\mathbb{R}^n$ , which has all of its entries equal to  1 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "manufactured-devon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Hx dot 1-vector equal to 0(perpendicular to 1-vector)? True\n",
      "Is all feature in HX perpendicular to 1-vector? True\n"
     ]
    }
   ],
   "source": [
    "X = np.random.random((n,n))\n",
    "_1vec = np.ones(n)\n",
    "print('Is Hx dot 1-vector equal to 0(perpendicular to 1-vector)?', np.allclose(0,H@x@_1vec))\n",
    "print('Is all feature in HX perpendicular to 1-vector?', np.allclose(0, np.sum(H@X@_1vec,axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-tunisia",
   "metadata": {},
   "source": [
    "- The matrix  ùêª centering all columns(features) in a matrix\n",
    "- The matrix  ùêª  is a projections onto the subspace  ${ùê±:\\frac{1}{ùëõ}\\sum\\limits_{i=1}^{n}{x^i}=0}\\subset \\mathbb{R}^n$ . (In other words, this is the set of vectors having coordinate-wise average equal to  0 .)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "major-prefix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Hx centered? True\n",
      "Is all features in X centered? True\n"
     ]
    }
   ],
   "source": [
    "print('Is Hx centered?',np.allclose(0,np.sum(H@x)))      \n",
    "print('Is all features in X centered?', np.allclose(0,np.sum(H@X, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-entity",
   "metadata": {},
   "source": [
    "### 7. Measuring the Spread of a Point Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "published-traffic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.],\n",
       "        [2.]]),\n",
       " array([[2.2],\n",
       "        [4.4]]),\n",
       " array([[-0.2],\n",
       "        [-0.4]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Projection onto a Line\n",
    "u= 1/np.sqrt(5)*np.array([[1,2]]).T\n",
    "x1=np.array([[1,2]]).T\n",
    "x2=np.array([[3,4]]).T\n",
    "x3=np.array([[-1,0]]).T\n",
    "u.T@x1*u, u.T@x2*u, u.T@x3*u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "subsequent-portuguese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(4.8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empirical Variance of a Data Set in a Given Direction\n",
    "X = np.vstack([u.T@x1, u.T@x2, u.T@x3])\n",
    "S = cov_matrix(X)\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ideal-davis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.8]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ùêÆ^TùëÜùêÆ\n",
    "u.T*S@u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-judge",
   "metadata": {},
   "source": [
    "#### Variance of a Random Vector in a Given Direction\n",
    "- Let $x \\sim \\mathcal{N}(0,\\Sigma)$, $x \\in \\mathbb{R}^2$, $\\Sigma \\in \\mathbb{R}^{2\\times 2}$\n",
    "$$\\Sigma =E[XX^T]= \\begin{bmatrix}E[(X^1)^2]&E[X^1 X^2]\\\\ E[X^1 X^2] & E[(X^2)^2]\\end{bmatrix}=\\begin{bmatrix}Var(X^1)&Var(X^1 X^2) \\\\ Var(X^1 X^2)&Var(X^2)\\end{bmatrix}$$\n",
    "- $Var(X^1 + X^2)=E[(X^1)^2] + E[(X^2)^2]+2*E[X^1 X^2]=\\begin{bmatrix}1&1\\end{bmatrix}\\Sigma\\begin{bmatrix}1\\\\1\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-wagner",
   "metadata": {},
   "source": [
    "#### A Preview of Principal Component Analysis\n",
    "- Let $X_1,\\dots,X_n \\in \\mathbb{R}^d$, $\\mathbb{X} = \\begin{bmatrix}-X_1^T- \\\\ \\vdots \\\\ -X_n^T-\\end{bmatrix}$\n",
    "- ***Feature Centered*** empirical covariance matrix \n",
    "    - $S= \\frac{1}{n} \\mathbb{X}^T (I_n-\\frac{1}{n} 1 1^T) \\mathbb{X}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-editor",
   "metadata": {},
   "source": [
    "### 8. The Decomposition Theorem for Symmetric Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-collar",
   "metadata": {},
   "source": [
    "#### Orthogonal Matrices\n",
    "- Marix $P \\in \\mathbb{R}^{d\\times d}$ is orthogonal matrix/rotation matrix\n",
    "    - if $PP^T=P^TP=I_d$\n",
    "- Let $P=\\begin{bmatrix}v_1&v_2&\\dots&v_d \\end{bmatrix}$\n",
    "    - $v_i.T v_i = \\sum_{l=1}^d v_{i,l}^2 = 1$\n",
    "    - $v_i.T v_j = \\sum_{l=1}^d v_{i,l}*v_{j,l} = 0$\n",
    "- $det(P)=\\pm1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-premium",
   "metadata": {},
   "source": [
    "#### Eigenvectors and Eigenvalues of a Decomposition of a Symmetric Matrix\n",
    "- $A \\in \\mathbb{R}^{d\\times d}$\n",
    "$$\\begin{align}  A &= PDP^T \\\\\n",
    "    &= \\begin{bmatrix}v_1&v_2&\\dots&v_d\\end{bmatrix} \\begin{bmatrix} \\lambda_1&0&\\dots&0 \\\\ 0&\\lambda_2&\\dots&0 \\\\ \\vdots&\\vdots&\\ddots&\\vdots \\\\ 0&0&\\dots&\\lambda_d\\end{bmatrix}\\begin{bmatrix}-v_1^T- \\\\ -v_2^T- \\\\ \\vdots \\\\ -v_d^T-\\end{bmatrix} \\\\\n",
    "    &= \\lambda_1 v_1\\otimes v_1^T + \\lambda_2 v_2 \\otimes v_2^T + \\dots + \\lambda_d v_d \\otimes v_d^T\n",
    "    \\end{align}$$\n",
    "    \n",
    "- $P \\in \\mathbb{R}^{d\\times d} s.t. P \\text{ is orthogonal}$\n",
    "- $D \\text{ is diagonal}$\n",
    "    - $D = diag(\\lambda_1, \\lambda_2, \\dots, \\lambda_d)$\n",
    "    - $\\lambda \\geq 0$\n",
    "$$\\begin{align}\n",
    "    Av_1 &= (\\lambda_1 v_1\\otimes v_1^T + \\lambda_2 v_2 \\otimes v_2^T + \\dots + \\lambda_d v_d \\otimes v_d^T) v_1\\\\\n",
    "    &= \\lambda_1 \n",
    "    \\begin{bmatrix}v_{1,1}^2     & v_{1,1}v_{1,2}& \\dots &v_{1,1}v_{1,d}\\\\\n",
    "                   v_{1,2}v_{1,1}& v_{1,2}^2     & \\dots &v_{1,2}v_{1,d}\\\\\n",
    "                    \\vdots       &\\vdots         &\\vdots &\\vdots \\\\\n",
    "                   v_{1,d}v_{1,1}&v_{1,d}v_{1,2} & \\dots &v_{1,d}^2\\end{bmatrix} \n",
    "    \\begin{bmatrix}v_{1,1}\\\\ v_{1,2}\\\\ \\vdots \\\\ v_{1,d}\\end{bmatrix} +\n",
    "    \\lambda_2 \n",
    "    \\begin{bmatrix}v_{2,1}^2     & v_{2,1}v_{2,2}& \\dots &v_{2,1}v_{2,d}\\\\\n",
    "                   v_{2,2}v_{2,1}& v_{2,2}^2     & \\dots &v_{2,2}v_{2,d}\\\\\n",
    "                    \\vdots       &\\vdots         &\\vdots &\\vdots \\\\\n",
    "                   v_{2,d}v_{2,1}&v_{2,d}v_{2,2} & \\dots &v_{2,d}^2\\end{bmatrix} \n",
    "    \\begin{bmatrix}v_{1,1}\\\\ v_{1,2}\\\\ \\vdots \\\\ v_{1,d}\\end{bmatrix}\\\\\n",
    "    &= \\lambda_1 \n",
    "    \\begin{bmatrix}v_{1,1}*(v_{1,1}^2+v_{1,2}^2+\\dots +v_{1,d}^2) = v_{1,1}*\\sum_{l=1} v_{1,l}^2 = v_{1,1}*1\\\\\n",
    "                   v_{1,2}*(v_{1,1}^2+v_{1,2}^2+\\dots +v_{1,d}^2) = v_{1,2}*\\sum_{l=1} v_{1,l}^2 = v_{1,2}*1\\\\\n",
    "                    \\vdots\\\\\n",
    "                   v_{1,d}*(v_{1,1}^2+v_{1,2}^2+\\dots +v_{1,d}^2) = v_{1,d}*\\sum_{l=1} v_{1,l}^2 = v_{1,d}*1\\\\\\end{bmatrix} + \n",
    "   \\lambda_2\n",
    "   \\begin{bmatrix}v_{2,1}*\\sum_{l=1}^d v_{i,l}*v_{j,l} = 0\\\\\n",
    "                  v_{2,2}*\\sum_{l=1}^d v_{i,l}*v_{j,l} = 0\\\\\n",
    "                    \\vdots\\\\\n",
    "                   v_{2,d}*\\sum_{l=1}^d v_{i,l}*v_{j,l} = 0\\\\\n",
    "                   \\end{bmatrix}\\\\\n",
    "    &= \\lambda_1 v_1\n",
    "   \\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aggregate-ticket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P is orthogonal? True\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ortho_group\n",
    "d = 20\n",
    "P = ortho_group.rvs(dim=d)\n",
    "lambdas = np.random.random(d)\n",
    "D = np.diag(lambdas)\n",
    "print(f'P is orthogonal? {np.allclose(P@P.T, P.T@P, np.eye(d))}')\n",
    "# print('-----')\n",
    "# print(f'P = \\n {P}')\n",
    "# print('-----')\n",
    "# print(f'D = \\n {D}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "phantom-remainder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is A@v_k == lambdas[:k] * v[:k] == outer_sum ?\n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "A = P@D@P.T\n",
    "# P is A's e-vectors matrix, D is A's e-values matrix\n",
    "# first k e-vectors\n",
    "k = 2\n",
    "v_k = P[:,:k]\n",
    "outer_sum=np.zeros(shape=v_k.shape)\n",
    "for kk in range(k):\n",
    "    outer_sum += (np.outer(P[:,kk],P[:,kk])*lambdas[kk])@v_k\n",
    "# print(f'Av[:k] =\\n{A@v_k}')\n",
    "# print('-----')\n",
    "# print(f'lambdas[:k] * v[:k] =\\n {lambdas[:k]*v_k}')\n",
    "# print('-----')\n",
    "# print(f'( sum(lambda_kk*outer(v_kk, v_kk)) )@v_k = \\n {outer_sum}')\n",
    "\n",
    "print('Is A@v_k == lambdas[:k] * v[:k] == outer_sum ?\\n', (np.allclose(A@v_k, lambdas[:k]*v_k)*np.allclose(A@v_k, outer_sum)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "given-soccer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is A symmetric = \n",
      " True\n",
      "-----\n",
      "all e-values >= 0 ? True\n",
      "-----\n",
      "all e-values > 0 ? True\n"
     ]
    }
   ],
   "source": [
    "# A is symmetric\n",
    "print(f'Is A symmetric = \\n {np.allclose(A,A.T)}')\n",
    "print('-----')\n",
    "# A is positive semidefinite\n",
    "## all lambda(e-values) >=0 \n",
    "print(f'all e-values >= 0 ? {(np.diag(D)>=0).all()}')\n",
    "print('-----')\n",
    "# A is positive definite\n",
    "## all e-values = lambda >0 \n",
    "print(f'all e-values > 0 ? {(np.diag(D>0)).all()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-knight",
   "metadata": {},
   "source": [
    "#### Concept Check: The Decomposition Theorem for Symmetric Matrices\n",
    "- P\n",
    "    - The columns of  ùëÉ  are unit vectors.\n",
    "    - The columns of  ùëÉ  are eigenvectors of  ùê¥ .\n",
    "    - The dot product of any two different columns of  ùëÉ  is  0 .\n",
    "    - The rows of  ùëÉ  are unit vectors.\n",
    "- D\n",
    "    - The diagonal entries of  ùê∑  are the eigenvalues of  ùê¥ .\n",
    "    - The first diagonal element of  ùê∑  (i.e. in the top left corner) is the eigenvalue corresponding to the eigenvector which is in the first (i.e. leftmost) column of  ùëÉ .\n",
    "    - It is possible for any of the diagonal entries of  ùê∑  to be zero.\n",
    "    - It is possible for all of the diagonal entries of  ùê∑  to be the same\n",
    "\n",
    "#### Concept Check: Properties of Covariance Matrices\n",
    "- Let  Œ£  denote a covariance matrix for some random vector  ùëã‚àà‚Ñùùëë . (Assume that  $E[||X||_2^2]<\\infty$ .)\n",
    "- Œ£ definitely\n",
    "    - Symmetric\n",
    "    - Positive Semidefinite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-toyota",
   "metadata": {},
   "source": [
    "### 9. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-search",
   "metadata": {},
   "source": [
    "#### Centering Data\n",
    "- Why using centered data? for LESS computational cost, the result is the same\n",
    "    1. Let dataset $\\mathbb{X} \\in \\mathbb{R}^{n \\times d}$, feature vector $X_{1 \\leq i \\leq d} \\in \\mathbb{R}^n$\n",
    "        - $\\mathbb{X} = \\begin{bmatrix} X_1 & X_2 & \\dots & X_d \\end{bmatrix}$\n",
    "    2. Covariance(between each feature) matrix of X:\n",
    "        - $S = \\begin{bmatrix} Cov(X_1, X_1) & Cov(X_1, X_2) & \\dots & Cov(X_1, X_d) \\\\\n",
    "                               Cov(X_2, X_1) & Cov(X_2, X_2) & \\dots & Cov(X_2, X_d) \\\\\n",
    "                               \\vdots        & \\vdots        & \\ddots& \\vdots        \\\\\n",
    "                               Cov(X_d, X_1) & Cov(X_d, X_2) & \\dots & Cov(X_d, X_d)\n",
    "               \\end{bmatrix}\n",
    "             = \\begin{bmatrix} E[X_1^T X_1]-E[X_1]E[X_1] & E[X_1^T X_2]-E[X_1]E[X_2] & \\dots & E[X_1^T X_d]-E[X_1]E[X_d] \\\\\n",
    "                               E[X_2^T X_1]-E[X_2]E[X_1] & E[X_2^T X_2]-E[X_2]E[X_2] & \\dots & E[X_2^T X_d]-E[X_2]E[X_d] \\\\\n",
    "                               \\vdots                    & \\vdots                    & \\ddots& \\vdots                    \\\\\n",
    "                               E[X_d^T X_1]-E[X_d]E[X_1] & E[X_d^T X_2]-E[X_d]E[X_2] & \\dots & E[X_d^T X_d]-E[X_d]E[X_d] \\\\\n",
    "               \\end{bmatrix}$\n",
    "    3. If data is centered, $0 = E[X_1] = E[X_2] = \\dots = E[X_d]$\n",
    "        - $S = \\begin{bmatrix} E[X_1^T X_1] & E[X_1^T X_2] & \\dots & E[X_1^T X_d] \\\\\n",
    "                               E[X_2^T X_1] & E[X_2^T X_2] & \\dots & E[X_2^T X_d] \\\\\n",
    "                               \\vdots       & \\vdots       & \\ddots& \\vdots       \\\\\n",
    "                               E[X_d^T X_1] & E[X_d^T X_2] & \\dots & E[X_d^T X_d] \\\\\n",
    "               \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "right-engineer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original vector =\n",
      " [0.03123444 0.54400361 0.44931098]\n",
      "-----\n",
      "expectation of x =\n",
      " 0.3415163418226597\n",
      "-----\n",
      "centered data =\n",
      " [-0.3102819   0.20248727  0.10779463]\n",
      "-----\n",
      "compare with using H, has same result?  True\n"
     ]
    }
   ],
   "source": [
    "n=3\n",
    "x = np.random.random(n)\n",
    "H = np.identity(n)-1/n*np.outer(np.ones(n),np.ones(n)) \n",
    "print(f'original vector =\\n {x}')\n",
    "print('-----')\n",
    "print(f'expectation of x =\\n {np.mean(x)}')\n",
    "print('-----')\n",
    "print(f'centered data =\\n {x-np.mean(x)}')\n",
    "print('-----')\n",
    "print('compare with using H, has same result? ', np.allclose(H@x, x-np.mean(x, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "given-findings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset =\n",
      " [[0.15430676 0.86491224 0.03367474 0.8072289 ]\n",
      " [0.5207967  0.65733124 0.69992944 0.42691473]\n",
      " [0.85930624 0.3002285  0.61577759 0.95626665]]\n",
      "-----\n",
      "expectation of each feature = [0.5114699  0.60749066 0.44979393 0.73013676]\n",
      "-----\n",
      "feature centered data set =\n",
      " [[-0.35716314  0.25742158 -0.41611918  0.07709214]\n",
      " [ 0.0093268   0.04984058  0.25013551 -0.30322203]\n",
      " [ 0.34783634 -0.30726217  0.16598367  0.22612989]]\n",
      "-----\n",
      "compare with using H, has same result?  True\n"
     ]
    }
   ],
   "source": [
    "X = np.random.random((n,n+1))\n",
    "print(f'original dataset =\\n {X}')\n",
    "print('-----')\n",
    "print(f'expectation of each feature = {np.mean(X, axis=0)}')\n",
    "print('-----')\n",
    "print(f'feature centered data set =\\n {X-np.mean(X, axis=0)}')\n",
    "print('-----')\n",
    "print('compare with using H, has same result? ', np.allclose(H@X, X-np.mean(X, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "measured-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.scatterplot(x=X[:,0], y=X[:,1])\n",
    "# sns.scatterplot(x=H@X[:,0], y=H@X[:,1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-realtor",
   "metadata": {},
   "source": [
    "#### Conceptual Example I: 2 data points in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "republican-offering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0,1],[0,-1]])\n",
    "S = cov_matrix(X)\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "nonprofit-vatican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]])),\n",
       " (array([ 0., -1.]),\n",
       "  array([[ 1.        , -0.70710678],\n",
       "         [ 0.        ,  0.70710678]])))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eig(S), np.linalg.eig(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-consumer",
   "metadata": {},
   "source": [
    "#### 10. Conceptual Examples in 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hydraulic-watts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ds = \n",
      "[[ 1.   0.5]\n",
      " [-1.  -0.5]]\n",
      "-----\n",
      "covariance matrix XS = \n",
      "[[1.   0.5 ]\n",
      " [0.5  0.25]]\n",
      "-----\n",
      "double check S, True\n",
      "-----\n",
      "e_values_matrix = \n",
      " [[1.25 0.  ]\n",
      " [0.   0.  ]]\n",
      "-----\n",
      "e_vectors_matrix = \n",
      " [[ 0.89442719 -0.4472136 ]\n",
      " [ 0.4472136   0.89442719]]\n",
      "-----\n",
      "PC1 e-value, e-vector = \n",
      "1.25, [0.89442719 0.4472136 ]\n",
      "-----\n",
      "x_1 projected on PC1 = \n",
      " 1.118033988749895\n",
      "x_2 projected on PC1 = \n",
      " -1.118033988749895\n",
      "-----\n",
      "Projected ds = \n",
      " [[ 1.11803399]\n",
      " [-1.11803399]]\n",
      "-----\n",
      "Projected covariance matrix YS = \n",
      " 1.2500000000000002\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "ùê±_1 \t = \t np.array((1,1/2))\n",
    "ùê±_2 \t = \t np.array((-1,-1/2))\n",
    "X=np.vstack([x_1,x_2])\n",
    "print(f'Original ds = \\n{X}')\n",
    "print('-----')\n",
    "# covariance matrix\n",
    "XS =np.cov(X.T,bias=True)\n",
    "print(f'covariance matrix XS = \\n{XS}')\n",
    "print('-----')\n",
    "print(f'double check S, {np.allclose(XS, cov_matrix(X))}')\n",
    "print('-----')\n",
    "e_values, e_vectors = np.linalg.eig(XS)\n",
    "e_values_matrix = np.diag(e_values)\n",
    "print(f'e_values_matrix = \\n {e_values_matrix}')\n",
    "print('-----')\n",
    "print(f'e_vectors_matrix = \\n {e_vectors}')\n",
    "print('-----')\n",
    "PC1_value_ind = np.argmax(e_values)\n",
    "PC1_value = e_values[PC1_value_ind]\n",
    "PC1_vector = e_vectors[:,PC1_value_ind]\n",
    "print(f'PC1 e-value, e-vector = \\n{PC1_value}, {PC1_vector}')\n",
    "print('-----')\n",
    "x1_on_PC1 = PC1_vector@x_1\n",
    "x2_on_PC1 = PC1_vector@x_2\n",
    "print(f'x_1 projected on PC1 = \\n {x1_on_PC1}')\n",
    "print(f'x_2 projected on PC1 = \\n {x2_on_PC1}')\n",
    "print('-----')\n",
    "Y = np.vstack([x1_on_PC1, x2_on_PC1])\n",
    "print(f'Projected ds = \\n {Y}')\n",
    "print('-----')\n",
    "YS = cov_matrix(Y)\n",
    "print(f'Projected covariance matrix YS = \\n {YS}')\n",
    "print('-----')\n",
    "# np.array(np.dot(e_vectors[:,1],x_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-fiber",
   "metadata": {},
   "source": [
    "#### 11. Conceptual Examples in 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caring-disney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ds = \n",
      "[[ 0  2]\n",
      " [ 1 -1]\n",
      " [-1 -1]]\n",
      "-----\n",
      "covariance matrix XS = \n",
      "[[0.66666667 0.        ]\n",
      " [0.         2.        ]]\n",
      "-----\n",
      "double check S, True\n",
      "-----\n",
      "e_values_matrix = \n",
      " [[0.66666667 0.        ]\n",
      " [0.         2.        ]]\n",
      "-----\n",
      "e_vectors_matrix = \n",
      " [[1. 0.]\n",
      " [0. 1.]]\n",
      "-----\n",
      "PC1 e-value, e-vector = \n",
      "2.0, [0. 1.]\n",
      "-----\n",
      "x_1 projected on PC1 = \n",
      " 2.0\n",
      "x_2 projected on PC1 = \n",
      " -1.0\n",
      "x_3 projected on PC1 = \n",
      " -1.0\n",
      "-----\n",
      "Projected ds = \n",
      " [[ 2.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "-----\n",
      "Projected covariance matrix YS = \n",
      " 2.0\n"
     ]
    }
   ],
   "source": [
    "ùê±_1 \t = \t np.array((0,2))\n",
    "ùê±_2 \t = \t np.array((1,-1))\n",
    "ùê±_3 \t = \t np.array((-1,-1))\n",
    "X=np.vstack([x_1,x_2,x_3])\n",
    "\n",
    "print(f'Original ds = \\n{X}')\n",
    "print('-----')\n",
    "# covariance matrix\n",
    "XS =np.cov(X.T,bias=True)\n",
    "print(f'covariance matrix XS = \\n{XS}')\n",
    "print('-----')\n",
    "print(f'double check S, {np.allclose(XS, cov_matrix(X))}')\n",
    "print('-----')\n",
    "e_values, e_vectors = np.linalg.eig(XS)\n",
    "e_values_matrix = np.diag(e_values)\n",
    "print(f'e_values_matrix = \\n {e_values_matrix}')\n",
    "print('-----')\n",
    "print(f'e_vectors_matrix = \\n {e_vectors}')\n",
    "print('-----')\n",
    "PC1_value_ind = np.argmax(e_values)\n",
    "PC1_value = e_values[PC1_value_ind]\n",
    "PC1_vector = e_vectors[:,PC1_value_ind]\n",
    "print(f'PC1 e-value, e-vector = \\n{PC1_value}, {PC1_vector}')\n",
    "print('-----')\n",
    "x1_on_PC1 = PC1_vector@x_1\n",
    "x2_on_PC1 = PC1_vector@x_2\n",
    "x3_on_PC1 = PC1_vector@x_3\n",
    "print(f'x_1 projected on PC1 = \\n {x1_on_PC1}')\n",
    "print(f'x_2 projected on PC1 = \\n {x2_on_PC1}')\n",
    "print(f'x_3 projected on PC1 = \\n {x3_on_PC1}')\n",
    "print('-----')\n",
    "Y = np.vstack([x1_on_PC1, x2_on_PC1, x3_on_PC1])\n",
    "print(f'Projected ds = \\n {Y}')\n",
    "print('-----')\n",
    "YS = cov_matrix(Y)\n",
    "print(f'Projected covariance matrix YS = \\n {YS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-robinson",
   "metadata": {},
   "source": [
    "#### 12. Conceptual Examples Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "committed-courage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ds = \n",
      "[[ 0  2]\n",
      " [ 0 -2]\n",
      " [ 1  1]\n",
      " [-1 -1]]\n",
      "-----\n",
      "covariance matrix XS = \n",
      "[[0.5 0.5]\n",
      " [0.5 2.5]]\n",
      "-----\n",
      "double check S, True\n",
      "-----\n",
      "e_values_matrix = \n",
      " [[0.38196601 0.        ]\n",
      " [0.         2.61803399]]\n",
      "-----\n",
      "e_vectors_matrix = \n",
      " [[-0.97324899 -0.22975292]\n",
      " [ 0.22975292 -0.97324899]]\n",
      "-----\n",
      "PC1 e-value, e-vector = \n",
      "2.618033988749895, [-0.22975292 -0.97324899]\n",
      "-----\n",
      "Projected ds = \n",
      " [[-1.94649798]\n",
      " [ 1.94649798]\n",
      " [-1.20300191]\n",
      " [ 1.20300191]]\n",
      "-----\n",
      "Projected covariance matrix YS = \n",
      " 2.6180339887498945\n"
     ]
    }
   ],
   "source": [
    "ùê±_1 \t = \t np.array((0,2))\n",
    "ùê±_2 \t = \t np.array((0,-2))\n",
    "ùê±_3 \t = \t np.array((1,1))\n",
    "ùê±_4 \t = \t np.array((-1,-1))\n",
    "X=np.vstack([x_1,x_2,x_3,x_4])\n",
    "print(f'Original ds = \\n{X}')\n",
    "print('-----')\n",
    "# covariance matrix\n",
    "XS =np.cov(X.T,bias=True)\n",
    "print(f'covariance matrix XS = \\n{XS}')\n",
    "print('-----')\n",
    "print(f'double check S, {np.allclose(XS, cov_matrix(X))}')\n",
    "print('-----')\n",
    "e_values, e_vectors = np.linalg.eig(XS)\n",
    "e_values_matrix = np.diag(e_values)\n",
    "print(f'e_values_matrix = \\n {e_values_matrix}')\n",
    "print('-----')\n",
    "print(f'e_vectors_matrix = \\n {e_vectors}')\n",
    "print('-----')\n",
    "PC1_value_ind = np.argmax(e_values)\n",
    "PC1_value = e_values[PC1_value_ind]\n",
    "PC1_vector = e_vectors[:,PC1_value_ind]\n",
    "print(f'PC1 e-value, e-vector = \\n{PC1_value}, {PC1_vector}')\n",
    "print('-----')\n",
    "x1_on_PC1 = PC1_vector@x_1\n",
    "x2_on_PC1 = PC1_vector@x_2\n",
    "x3_on_PC1 = PC1_vector@x_3\n",
    "x4_on_PC1 = PC1_vector@x_4\n",
    "# print(f'x_1 projected on PC1 = \\n {x1_on_PC1}')\n",
    "# print(f'x_2 projected on PC1 = \\n {x2_on_PC1}')\n",
    "# print(f'x_2 projected on PC1 = \\n {x3_on_PC1}')\n",
    "# print(f'x_2 projected on PC1 = \\n {x4_on_PC1}')\n",
    "# print('-----')\n",
    "Y = np.vstack([x1_on_PC1, x2_on_PC1, x3_on_PC1, x4_on_PC1])\n",
    "print(f'Projected ds = \\n {Y}')\n",
    "print('-----')\n",
    "YS = cov_matrix(Y)\n",
    "print(f'Projected covariance matrix YS = \\n {YS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-pressing",
   "metadata": {},
   "source": [
    "### 13. Covariance versus Correlation\n",
    "\n",
    "- Áî® Correlation ‰æÜÂÅöËÉΩÂ§†ÈÅøÂÖç data Ë¢´ rescal ÂæåÁöÑ Áõ∏ÈóúÊÄßË¢´ÊîπËÆäÔºåex: cm/age vs inch/age, Èªû‰πãÈñìÁöÑË∑ùÈõ¢‰∏¶‰∏ç‰∏ÄÂÆöÁõ∏Âêå\n",
    "- IF each covariate  $X_i$  represents a particular physical characteristics, such as age, height, weight, blood pressure, etc of individuals.\n",
    "    - use the correlation matrix instead of the covariance matrix for PCA\n",
    "- ***random variables***\n",
    "    - Recall that the correlation  $\\rho_{X,Y}$ of two random variables  $X$  and  $Y$  is the covariance of the the rescaled random variables  $\\frac{X}{\\sigma_{X}}$ , and  $\\frac{Y}{\\sigma_{Y}}$\n",
    "        - $\\rho_{X,Y} = Cov(\\frac{X}{\\sigma_{X}}, \\frac{Y}{\\sigma_{Y}}) = \\frac{Cov(X,Y)}{\\sigma_{X}\\sigma_{Y}} = \\frac{E[XY]-E[X]E[Y]}{\\sqrt{(E[X^2] - E[X]^2)(E[Y^2] - E[Y]^2)}}$\n",
    "        - if $E[X] = E[Y] = 0$, then\n",
    "            - $\\rho_{X,Y} = \\frac{E[XY]}{\\sqrt{(E[X^2])(E[Y^2])}}$\n",
    "- ***random vectors***\n",
    "    - Extending to random vectors $X$  with  $E[X]=0$ , the correlation matrix is the covariance matrix of rescaled data:\n",
    "$$E[\\tilde{X}\\tilde{X}^T]=E[\\begin{bmatrix} \\frac{X_1}{\\sigma_{X_1}} \\\\ \\frac{X_2}{\\sigma_{X_2}} \\\\ \\vdots \\\\ \\frac{X_n}{\\sigma_{X_n}} \\end{bmatrix} \\begin{bmatrix} \\frac{X_1}{\\sigma_{X_1}} & \\frac{X_2}{\\sigma_{X_2}} & \\dots & \\frac{X_n}{\\sigma_{X_n}} \\end{bmatrix}] $$\n",
    "\t \n",
    "    - so that  ùëñ,ùëó -th entry of the correlation matrix is  $E[\\frac{X_i X_j}{\\sigma_{X_i}\\sigma_{X_j}}]$\n",
    "\n",
    "    - By definition, covariance has the dimension of squared of the data, while correlation is dimensionless. Hence, when covariates have different dimensions or units, it makes more sense to first rescale each covariate by its sample standard deviation, before determining the directions of largest spread using PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "underlying-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_matrix(X):\n",
    "    n=X.shape[0]\n",
    "    S = 1/n*(X.T@(np.identity(X.shape[0])-1/n*np.ones((n,n)))@X)\n",
    "    return np.squeeze(S)\n",
    "def corr_matrix(X):\n",
    "    cov = cov_matrix(X)\n",
    "    std = np.outer(np.std(X, axis=0), np.std(X, axis=0))\n",
    "    return cov/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "internal-dollar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(corr_matrix(X), np.corrcoef(X.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "round-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference between centered or not centered data set, in cov and corr\n",
    "n, d = 20, 3\n",
    "X = np.random.random((n,d))\n",
    "H = np.identity(n)-1/n*np.outer(np.ones(n),np.ones(n)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "weekly-vatican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled feature in dataset or scaled dataset wont change Correlation matrix\n",
      "scaled feature in dataset or scaled dataset will change Covariance matrix, scaled = scalar^2 * original\n",
      "add any constant to feature in dataset or data set wont change any result\n"
     ]
    }
   ],
   "source": [
    "# for scalar in range(1,3):\n",
    "#     X_temp = X.copy()\n",
    "#     X_temp = scalar*X_temp\n",
    "#     corr = corr_matrix(X_temp)\n",
    "#     cov  = cov_matrix(X_temp)\n",
    "#     print(f'scalar = {scalar}')\n",
    "#     print('scaled dataset corr =\\n', corr)\n",
    "#     print('-----')\n",
    "#     print('scaled dataset cov =\\n', cov)\n",
    "#     print('-----')\n",
    "#     X_temp[:,0] = scalar*X_temp[:,0]-8\n",
    "#     corr = corr_matrix(X_temp)\n",
    "#     cov  = cov_matrix(X_temp)\n",
    "#     print('scaled feature corr =\\n', corr)\n",
    "#     print('-----')\n",
    "#     print('scaled feature cov =\\n', cov)\n",
    "#     print('-----')\n",
    "    \n",
    "print('scaled feature in dataset or scaled dataset wont change Correlation matrix')\n",
    "print('scaled feature in dataset or scaled dataset will change Covariance matrix, scaled = scalar^2 * original')\n",
    "print('add any constant to feature in dataset or data set wont change any result')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-surgery",
   "metadata": {},
   "source": [
    "#### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fourth-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = 40, 5\n",
    "X = np.random.random((n,d))\n",
    "# wnat x in R^5 -> y in R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "genuine-cradle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cov version\n",
    "cov_X = cov_matrix(X)\n",
    "e_values, e_vectors = np.linalg.eig(cov_X)\n",
    "sorted_indices = np.argsort(e_values)[::-1]\n",
    "e_values_matrix_cov = np.diag(np.take_along_axis(e_values, np.argsort(e_values)[::-1], axis=0))\n",
    "e_vectors_cov = e_vectors[:,sorted_indices]\n",
    "Y_cov = X@e_vectors_cov[:,:2]\n",
    "Y_cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "daily-exchange",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corr version\n",
    "corr_X = corr_matrix(X)\n",
    "e_values, e_vectors = np.linalg.eig(corr_X)\n",
    "sorted_indices = np.argsort(e_values)[::-1]\n",
    "e_values_matrix_corr = np.diag(np.take_along_axis(e_values, np.argsort(e_values)[::-1], axis=0))\n",
    "e_vectors_corr = e_vectors[:,sorted_indices]\n",
    "Y_corr = X@e_vectors_corr[:,:2]\n",
    "Y_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "scenic-universal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=Y_cov[:,0], y=Y_cov[:,1], label='cov')\n",
    "sns.scatterplot(x=Y_corr[:,0], y=Y_corr[:,1], label='corr')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-signature",
   "metadata": {},
   "source": [
    "### 14. Total Variance\n",
    "- We can decide how many principal components to retain in the projection of the data based on their explained variance.\n",
    "- The total variance is the sum of variance of all the principal components, which equals the sum of the eigenvalues of the covariance matrix:\n",
    "    - Total Variance:$\\sum\\limits_{j=1}^{p}\\lambda_j$\n",
    "\n",
    "- The fraction of variance explained by a principal component is the ratio of the variance of that principal component to the total variance:\n",
    "    - $\\frac{\\lambda_j}{\\sum\\limits_{j=1}^{p}\\lambda_j}$\n",
    "    \n",
    "Ungraded Exercise: Compare the explained variance of the first principal component when PCA is applied to the correlation matrix with when PCA is applied to the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "opposite-carry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_values_cov =\n",
      " [92.96583171 69.74150583 65.19818689 54.22897394 49.11649813 42.76532033\n",
      " 40.01045301 38.6180372  31.58203834 29.57128277 27.56687888 23.52238744\n",
      " 20.63142154 17.72814188 16.16701826 13.21853763  9.33039559  7.61572927\n",
      "  6.12413831  5.10784803]\n",
      "-----\n",
      "e_values_corr =\n",
      " [2.66685142 2.152507   1.86366106 1.63100182 1.52045339 1.29546385\n",
      " 1.2351152  1.17106642 0.96892218 0.94794266 0.82080173 0.77087402\n",
      " 0.66659711 0.53701483 0.49051541 0.39912747 0.29162359 0.24319229\n",
      " 0.18026559 0.14700295]\n"
     ]
    }
   ],
   "source": [
    "n, d = 40, 20\n",
    "X = np.random.randint(20, size=(n,d))\n",
    "\n",
    "cov  = cov_matrix(X)\n",
    "e_values_cov, e_vetors_cov = np.linalg.eig(cov)\n",
    "sorted_indices = np.argsort(e_values_cov)[::-1]\n",
    "e_values_cov = e_values_cov[sorted_indices]\n",
    "e_vetors_cov = e_vetors_cov[:,sorted_indices]\n",
    "# print('cov =\\n', cov)\n",
    "print('e_values_cov =\\n', e_values_cov)\n",
    "# print('e_vetors_cov =\\n', e_vetors_cov)\n",
    "print('-----')\n",
    "\n",
    "corr = corr_matrix(X)\n",
    "e_values_corr, e_vetors_corr = np.linalg.eig(corr)\n",
    "sorted_indices = np.argsort(e_values_corr)[::-1]\n",
    "e_values_corr = e_values_corr[sorted_indices]\n",
    "e_vetors_corr = e_vetors_corr[:,sorted_indices]\n",
    "# print('corr =\\n', corr)\n",
    "print('e_values_corr =\\n', e_values_corr)\n",
    "# print('e_vetors_corr =\\n', e_vetors_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "stylish-summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of variance in each principal component(e-value/sum(e-values)):\n",
      "Covariance base PCA fraction =\n",
      " [0.14068453 0.10553932 0.09866395 0.08206432 0.07432765 0.06471645\n",
      " 0.06054753 0.0584404  0.04779287 0.04475001 0.04171676 0.03559626\n",
      " 0.03122138 0.02682787 0.02446543 0.02000352 0.01411962 0.01152483\n",
      " 0.00926761 0.00772967]\n",
      "Covariance base PCA Summation =\n",
      " 660.8106250000002\n",
      "-----\n",
      "Correlation base PCA fraction =\n",
      " [0.13334257 0.10762535 0.09318305 0.08155009 0.07602267 0.06477319\n",
      " 0.06175576 0.05855332 0.04844611 0.04739713 0.04104009 0.0385437\n",
      " 0.03332986 0.02685074 0.02452577 0.01995637 0.01458118 0.01215961\n",
      " 0.00901328 0.00735015]\n",
      "Correlation base PCA Summation =\n",
      " 20.000000000000014\n"
     ]
    }
   ],
   "source": [
    "print('Fraction of variance in each principal component(e-value/sum(e-values)):')\n",
    "print('Covariance base PCA fraction =\\n', e_values_cov / np.sum(e_values_cov))\n",
    "print('Covariance base PCA Summation =\\n',np.sum(e_values_cov))\n",
    "print('-----')\n",
    "print('Correlation base PCA fraction =\\n', e_values_corr / np.sum(e_values_corr))\n",
    "print('Correlation base PCA Summation =\\n', np.sum(e_values_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "reported-panic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference between two PCA is about 10%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.05218739, -0.01976541,  0.05555117,  0.00626616, -0.02280476,\n",
       "       -0.00087673, -0.01995502, -0.00193224, -0.01366806, -0.05915355,\n",
       "        0.01622068, -0.08280196, -0.06753296, -0.00085251, -0.00246622,\n",
       "        0.00235684, -0.03268916, -0.05507985,  0.02744347,  0.04909941])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The difference between two PCA is about 10%')\n",
    "(e_values_cov / np.sum(e_values_cov)- (e_values_corr / np.sum(e_values_corr))) / ((e_values_cov / np.sum(e_values_cov)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-drinking",
   "metadata": {},
   "source": [
    "### 15. Multidimensional Scaling (MDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "durable-invalid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given dataset X_origin\n",
    "n, d = 5,5\n",
    "X_origin = np.random.randint(10, size=(n,d))\n",
    "X_origin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "neutral-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. compute distance matrix\n",
    "from sklearn.metrics import pairwise_distances\n",
    "X_distance_matrix = pairwise_distances(X_origin)\n",
    "# print('distance matrix=\\n',X_distance_matrix)\n",
    "# print('-----')\n",
    "\n",
    "# 2. convert distance matrix into inner product representation\n",
    "H = np.identity(n)-1/n*np.outer(np.ones(n),np.ones(n)) \n",
    "XXT= (-1/2) * H@X_distance_matrix**2@H\n",
    "# print('inner product representation=\\n',XXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "vulnerable-production",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_values =\n",
      " [124.73958107  49.64400573  25.86994004   0.94647316   0.        ]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# 3. conpute e-vectors, e-values\n",
    "e_values, e_vectors = np.linalg.eig(XXT)\n",
    "e_values[np.isclose(0,e_values)] = 0\n",
    "sorted_indices = np.argsort(e_values)[::-1]\n",
    "\n",
    "e_values_matrix_MDS = np.diag(e_values[sorted_indices])\n",
    "e_vectors_MDS = e_vectors[:,sorted_indices]\n",
    "print('e_values =\\n', e_values[sorted_indices])\n",
    "# print('e_vectors_MDS =\\n', e_vectors_MDS)\n",
    "print('-----')\n",
    "# 4. output Y, k components\n",
    "k=2\n",
    "Y_MDS = e_vectors_MDS[:,:k]@np.sqrt(e_values_matrix_MDS[:k,:k])\n",
    "# print('Y_MDS =\\n',Y_MDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-postcard",
   "metadata": {},
   "source": [
    "#### check properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "rough-payroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is X = e-vectors @ e-values^0.5? True\n"
     ]
    }
   ],
   "source": [
    "X_inner = (e_vectors_MDS@np.sqrt(e_values_matrix_MDS))\n",
    "print('Is X = e-vectors @ e-values^0.5?', np.allclose(X_inner@X_inner.T, XXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "strange-playlist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first-1 compoments\n",
      "Is Y_MDSs same?\n",
      " True\n",
      "trace(X@X.T-Y@Y.T)^2 =\n",
      " 5846.195662501396\n",
      "-----\n",
      "first-2 compoments\n",
      "Is Y_MDSs same?\n",
      " True\n",
      "trace(X@X.T-Y@Y.T)^2 =\n",
      " 719.120016820741\n",
      "-----\n",
      "first-3 compoments\n",
      "Is Y_MDSs same?\n",
      " True\n",
      "trace(X@X.T-Y@Y.T)^2 =\n",
      " 0.8958114455916345\n",
      "-----\n",
      "first-4 compoments\n",
      "Is Y_MDSs same?\n",
      " True\n",
      "trace(X@X.T-Y@Y.T)^2 =\n",
      " 0.0\n",
      "-----\n",
      "first-5 compoments\n",
      "Is Y_MDSs same?\n",
      " True\n",
      "trace(X@X.T-Y@Y.T)^2 =\n",
      " 0.0\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for nn in range(1,n+1):\n",
    "    # determine Y by e-vec, e-val of XX.T\n",
    "    Y_MDS_eig = e_vectors_MDS[:,:nn]@np.sqrt(e_values_matrix_MDS[:nn,:nn])\n",
    "    # determine Y by X @ filter_matrix\n",
    "    filter_matrix = np.identity(n)[:,:nn]\n",
    "    Y_MDS_fil = X_inner@filter_matrix\n",
    "    print(f'first-{nn} compoments')\n",
    "    print('Is Y_MDSs same?\\n', np.allclose(Y_MDS_eig, Y_MDS_fil))\n",
    "    print('trace(X@X.T-Y@Y.T)^2 =\\n',(np.trace(X_inner@X_inner.T - Y_MDS_eig@Y_MDS_eig.T)**2))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-singing",
   "metadata": {},
   "source": [
    "### 16. Stochastic Neighbor Embedding (SNE) and t-distributed Stochastic Neighbor Embedding (t-SNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "pressing-steps",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 3.60555128, 1.41421356],\n",
       "       [3.60555128, 0.        , 3.60555128],\n",
       "       [1.41421356, 3.60555128, 0.        ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[-1,1],[2,3],[0,0]])\n",
    "X_distance_matrix = pairwise_distances(X)\n",
    "X_distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-exclusive",
   "metadata": {},
   "source": [
    "### 17. KL-divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "discrete-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "d12, d13 = 1 ,1\n",
    "d23 = np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "serious-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_finder(traget, ds):\n",
    "    ds = np.array(ds)\n",
    "    p_traget = np.exp(-traget**2) / np.sum(np.exp(-(ds**2)))\n",
    "    return p_traget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "cathedral-compromise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.42231879825151825, 0.42231879825151825, 0.15536240349696354)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p12 = p_finder(d12, [d12,d13,d23])\n",
    "p13 = p_finder(d13, [d12,d13,d23])\n",
    "p23 = p_finder(d23, [d12,d13,d23])\n",
    "p12,p13,p23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "danish-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_finder2(traget, ds):\n",
    "    ds = np.array(ds)\n",
    "    p_traget = (1/(1+traget**2)) / np.sum(1/(1+ds**2))\n",
    "    return p_traget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "conservative-market",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.157\n",
      "1.0242343445917418e-08\n",
      "1.1571\n",
      "7.96360893501075e-09\n",
      "1.1572\n",
      "5.971528694106738e-09\n",
      "1.1573\n",
      "4.265957624225347e-09\n",
      "1.1574\n",
      "2.846750887211709e-09\n",
      "1.1575\n",
      "1.7137632936328371e-09\n",
      "1.1576\n",
      "8.668499666735836e-10\n",
      "1.1577\n",
      "3.058660188343267e-10\n",
      "1.1578\n",
      "3.066673947677126e-11\n",
      "1.1579\n",
      "4.1107466567066636e-11\n",
      "1.158\n",
      "3.3704308333156005e-10\n",
      "1.1581\n",
      "9.183295801076243e-10\n",
      "1.1582\n",
      "1.7848218953744129e-09\n",
      "1.1582999999999999\n",
      "2.9363760230158254e-09\n",
      "1.1583999999999999\n",
      "4.372847067844569e-09\n",
      "1.1584999999999999\n",
      "6.0940910866198e-09\n",
      "1.1585999999999999\n",
      "8.099963162968237e-09\n",
      "1.1586999999999998\n",
      "1.039031992968565e-08\n",
      "1.1587999999999998\n",
      "1.296501653334347e-08\n",
      "1.1588999999999998\n",
      "1.5823909082268218e-08\n",
      "1.1589999999999998\n",
      "1.8966853570823216e-08\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for _d12 in np.arange(1.157,1.159, 0.0001):\n",
    "    _d13 = _d12\n",
    "    _d23 = _d12*2\n",
    "    q12 = p_finder2(_d12, [_d12,_d13,_d23])\n",
    "    q23 = p_finder2(_d23, [_d12,_d13,_d23])\n",
    "    print(_d12)\n",
    "    print(2*p12*np.log(p12/q12) + p23*np.log(p23/q23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "understanding-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "q12 = p_finder(_d12, [_d12,_d13,_d23])\n",
    "q23 = p_finder(_d23, [_d12,_d13,_d23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "contained-degree",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.40679038757564956, 0.18641922484870083)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q12, q23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "right-accident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03164218561047372"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*p12*np.log(p12/q12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "bored-birthday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.02831286526837094"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p23*np.log(p23/q23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "binding-florida",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003329320342102784\n"
     ]
    }
   ],
   "source": [
    "print(2*p12*np.log(p12/q12) + p23*np.log(p23/q23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "greek-concrete",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48 , 0.481, 0.482, 0.483, 0.484, 0.485, 0.486, 0.487, 0.488,\n",
       "       0.489, 0.49 , 0.491, 0.492, 0.493, 0.494, 0.495, 0.496, 0.497,\n",
       "       0.498, 0.499, 0.5  , 0.501, 0.502, 0.503, 0.504, 0.505, 0.506,\n",
       "       0.507, 0.508, 0.509, 0.51 , 0.511, 0.512, 0.513, 0.514, 0.515,\n",
       "       0.516, 0.517, 0.518, 0.519, 0.52 , 0.521, 0.522, 0.523, 0.524,\n",
       "       0.525, 0.526, 0.527, 0.528, 0.529, 0.53 , 0.531, 0.532, 0.533,\n",
       "       0.534, 0.535, 0.536, 0.537, 0.538, 0.539, 0.54 , 0.541, 0.542,\n",
       "       0.543, 0.544, 0.545, 0.546, 0.547, 0.548, 0.549, 0.55 , 0.551,\n",
       "       0.552, 0.553, 0.554, 0.555, 0.556, 0.557, 0.558, 0.559, 0.56 ,\n",
       "       0.561, 0.562, 0.563, 0.564, 0.565, 0.566, 0.567, 0.568, 0.569,\n",
       "       0.57 , 0.571, 0.572, 0.573, 0.574, 0.575, 0.576, 0.577, 0.578,\n",
       "       0.579, 0.58 , 0.581, 0.582, 0.583, 0.584, 0.585, 0.586, 0.587,\n",
       "       0.588, 0.589, 0.59 , 0.591, 0.592, 0.593, 0.594, 0.595, 0.596,\n",
       "       0.597, 0.598, 0.599])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.48,0.6, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "serial-friend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14450000000000002"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.05*0.99 + 0.95*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "romantic-norman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34256055363321797"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.05*0.99 / (0.05*0.99 + 0.95*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-mustang",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
